---
title: The Air War
author: Vivian Nguyen
date: '2022-10-10'
slug: []
categories: []
tags: []
---

This is blog post #5 in a series of analytical posts in lieu of the 2022 midterms. This post is affiliated with Gov 1347: Election Analytics, a course at Harvard University in the department of Government.

---

```{r setup, include = FALSE, message = FALSE}

# Set up
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(readr)
library(stargazer)
library(usmap)
library(rmapshaper)
library(sf)
library(insight)
library(scales)

# Load in expert ratings and district polls
creative <- read_csv("ads_2006_2018.csv") %>% 
  janitor::clean_names()
issues <- read_csv("ads_issues_2012-2018.csv") %>% 
  janitor::clean_names()
results <- read_csv("district_results_1948-2022.csv") %>% 
  janitor::clean_names()

```

```{r cleaning ad data, include = FALSE}

# Dropping unnecessary columns/variables from the ad data
creative2 <- creative %>%
  select(-c(x1, market, dma, airdate, race, station), -contains("fip")) %>%
  rename(year = 'cycle')

issues2 <- issues %>%
  select(-c(x1, market, dma, airdate, race), -contains("fip")) %>%
  rename(year = 'cycle')

# Joining ads data sets
compare_df_cols(creative2, issues2)
ads <- inner_join(creative2, issues2)

ads_df <- ads %>%
  group_by(state, district, year, party) %>%
  summarise(ads_ran = n(), total_airtime = sum(airtime), total_stations = sum(n_stations), total_cost = sum(est_cost))

```

```{r joining results with ad data, include = FALSE}

compare_df_cols(results, ads_df)

ads_results <- results %>%
  filter(year <= 2018) %>%
  left_join(ads_df, by = c("year", "state", "district")) # %>%
 # mutate(d_airtime = case_when(party = "Democrat" ~ ))

```

# The Plan This Week
We are about 4 weeks out from Election Day, and thus far I've created a national forecasting model that incorporates national economic conditions (Gross Domestic Product, Real Disposable Income, and unemployment), generic ballot polls (partisan preference), and the midterm-president's-party effect. I've also created a simple district-level forecasting model based on expert ratings ([Cook Political Report](https://www.cookpolitical.com/ratings/house-race-ratings), [Inside Elections](https://insideelections.com/ratings/house), and [Sabato's Crystal Ball](https://centerforpolitics.org/crystalball/2022-house/)).  

This week I plan to explore the impact of advertisements on the outcomes of congressional races. After evaluating the historical impact of "the Air War" on elections, I plan to update my simple district-level model from last week.  

# Are Advertisements Impactful?
To conduct this week's investigation, I compare the actual results of the 2018 midterm elections to the average election ratings of experts. The 2018 results shown below are Democrat vote shares in each district. The 2018 expert election ratings come from [Ballotpedia](https://ballotpedia.org/Main_Page), with the election ratings taking on integer values 1 through 7 -- 1 represents a Solid/Safe Democrat prediction and 7 represents a Solid/Safe Republican average expert prediction for each district.

NO EFFECT ?????????????

```{r, include = FALSE}

# dont just compare raw ad #s, compare the ratio of dem:rep ads, or proportionality, or log(ratio)

dem <- subset(ads_results, party == "Democrat")
rep <- subset(ads_results, party != "Democrat") 

dem$total_airtime <- as.numeric(dem$total_airtime)
reg <- lm(data = dem, dem_votes_major_percent ~ total_airtime + total_cost + ads_ran)

stargazer(reg, type = "text")

ggplot(data = dem, mapping = aes(x = ads_ran, y = dem_votes_major_percent)) + geom_point()
ggplot(data = dem, mapping = aes(x = total_cost, y = dem_votes_major_percent)) + geom_point()
ggplot(data = dem, mapping = aes(x = total_airtime, y = dem_votes_major_percent)) + geom_point()

ggplot(data = rep, mapping = aes(x = ads_ran, y = rep_votes_major_percent)) + geom_point()
ggplot(data = rep, mapping = aes(x = total_cost, y = rep_votes_major_percent)) + geom_point()
ggplot(data = rep, mapping = aes(x = total_airtime, y = rep_votes_major_percent)) + geom_point()


```

```{r, include = FALSE}
mmm <- issues %>%
  mutate(month = as.numeric(substr(airdate, 6, 7))) %>%
  filter(cycle %in% c(2012, 2014, 2016, 2018), month > 7) %>%
  group_by(cycle, airdate, party) %>%
  summarise(total_cost = sum(est_cost), ha = n()) 

issues %>%
  #mutate(year = as.numeric(substr(airdate, 1, 4))) %>%
  mutate(month = as.numeric(substr(airdate, 6, 7))) %>%
  filter(cycle %in% c(2012, 2014, 2016, 2018), month > 7) %>%
  group_by(cycle, airdate, party) %>%
  summarise(total_cost = sum(est_cost)) %>%
  ggplot(aes(x=airdate, y=total_cost, color=party)) +
  # scale_x_date(date_labels = "%b, %Y") +
  scale_y_continuous(labels = dollar_format()) +
  scale_color_manual(values = c("blue","red"), name = "") +
  geom_line() + geom_point(size=0.5) +
  facet_wrap(cycle ~ ., scales="free") +
  xlab("") + ylab("ad spend") +
  theme_bw() +
  theme(axis.title = element_text(size=15),
        axis.text = element_text(size=11),
        strip.text.x = element_text(size = 15))
```


## Actual Vote Share in 2018, by District

Below is the actual (D) vote share in the 2018 midterm elections at the district level.
```{r plotting actual 2018 vote share results, include = FALSE}
# require(tidyverse)
# require(ggplot2)
# require(sf)
# # load geographic data
# get_congress_map <- function(cong=114) {
#   tmp_file <- tempfile()
#   tmp_dir  <- tempdir()
#   zp <- sprintf("https://cdmaps.polisci.ucla.edu/shp/districts114.zip",cong)
#   download.file(zp, tmp_file)
#   unzip(zipfile = tmp_file, exdir = tmp_dir)
#   fpath <- paste(tmp_dir, sprintf("districtShapes/districts114.shp",cong), sep = "/")
#   st_read(fpath)
# }
# # load 114th congress
# cd114 <- get_congress_map(114)
# # vote data
# h <- district_results_48_22
# R_2014 <- h %>%
#   filter(year == 2018) %>%  
#   select(year, state, district, rep_votes_major_percent, dem_votes_major_percent) %>%
#   # summarize party vote share by district
#   group_by(state, district) %>%
#   summarise(Dem_votes_pct = dem_votes_major_percent) %>%
#   # rename district variable name to match shapefile
#   rename(DISTRICT = district, STATENAME = state) %>% drop_na()
# # merge
# cd114$DISTRICT <- as.numeric(cd114$DISTRICT)
# R_2014$DISTRICT <- as.numeric(R_2014$DISTRICT)
# cd114 <- cd114 %>% left_join(R_2014, by=c("DISTRICT", "STATENAME"))
# head(cd114$Dem_votes_pct)
# # plot with simplify
# districts_simp <- rmapshaper::ms_simplify(cd114, keep = 0.01)
# ggplot() + 
#   geom_sf(data=districts_simp,aes(fill=Dem_votes_pct),
#           inherit.aes=FALSE,alpha=0.9) + 
#   scale_fill_gradient2(low = "red", high = "blue", midpoint = 50, limits=c(0,100), name = "Democrat Major Vote Share") +
#   coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) +  
#   theme_void() +
#   theme(axis.title.x=element_blank(),
#         axis.text.x=element_blank(),
#         axis.ticks.x=element_blank(),
#         axis.title.y=element_blank(),
#         axis.text.y=element_blank(),
#         axis.ticks.y=element_blank()) + ggtitle("Actual (D) Vote Share in 2018 Midterm Elections")  
```

Most of the map is either red or white, which seems to suggest that most district vote share results were in the Republican party's favor or close between the two major parties. However, it is important to remember that for the House of Representatives, land is not proportional to representation, population is. Also, the president's party often performs poorly in midterm years, as discussed in detail in the [first blog post](https://vivian-1372.github.io/Election-Analytics/post/2022-09-15-analzying-2020-house-vote-shares/) of this series. Those two reminders considered, it then makes sense that the Democrats actually took the House in the 2018 midterms, with 235 seats going to Democrats and 199 going to Republicans (New York Times 2018).

## Expert Predictions for Vote Share in 2018, by District
```{r plotting expert predictions for 2018 midterms, include=FALSE}
# require(tidyverse)
# require(ggplot2)
# require(sf)
# # load geographic data
# get_congress_map <- function(cong=114) {
#   tmp_file <- tempfile()
#   tmp_dir  <- tempdir()
#   zp <- sprintf("https://cdmaps.polisci.ucla.edu/shp/districts114.zip",cong)
#   download.file(zp, tmp_file)
#   unzip(zipfile = tmp_file, exdir = tmp_dir)
#   fpath <- paste(tmp_dir, sprintf("districtShapes/districts114.shp",cong), sep = "/")
#   st_read(fpath)
# }
# # load 114th congress
# cd114 <- get_congress_map(114)
# # vote data
# h <- newdf2
# hh <- as.data.frame(h)
# hh["state" == "Alaska"]["district"] <- "0" 
# hh["state" == "Montana"]["district"] <- "0" 
# hh
# R_2014 <- hh %>%
#   select(state, district, avg_rating) %>%
#   # summarize party vote share by district
#   group_by(state, district) %>%
#   # rename district variable name to match shapefile
#   rename(DISTRICT = district, STATENAME = state) %>% drop_na()
# # merge
# cd114$DISTRICT <- as.numeric(cd114$DISTRICT)
# R_2014$DISTRICT <- as.numeric(R_2014$DISTRICT)
# cd114 <- cd114 %>% left_join(R_2014, by=c("DISTRICT", "STATENAME"))
# head(cd114$STATENAME)
# # plot with simplify
# districts_simp <- rmapshaper::ms_simplify(cd114, keep = 0.01)
# ggplot() + 
#   geom_sf(data=districts_simp, aes(fill = avg_rating),
#           inherit.aes=FALSE,alpha=0.9) + 
#   scale_fill_gradient2(low = "blue", high = "firebrick3", midpoint = 3.5, limits=c(0,7), name = "Expert Rating") +
#   coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) +  
#   theme_void() +
#   theme(axis.title.x=element_blank(),
#         axis.text.x=element_blank(),
#         axis.ticks.x=element_blank(),
#         axis.title.y=element_blank(),
#         axis.text.y=element_blank(),
#         axis.ticks.y=element_blank()) + ggtitle("Expert Ratings for 2018 Midterm Elections")
# #map of expert predictions at the district-level... wheres ALASKA???
```
Below are the expert ratings for the 2018 midterms, which I call predictions because the ratings reflect what the experts believed would happen in each congressional district election. Red areas represent high expert confidence that the region will go to Republicans, while blue areas represent high confidence that the region will go to Democrats. 

## Evaluation
For the most part, the predictions are pretty accurate via visual investigation. Most of the areas that actually had majority-Republican vote shares in the 2018 elections were predicted to be likely or solidly Republican by the experts on average. The blue districts of the 2018 midterms, like the ones along the west coast of Washington, Oregon, and California, in Arizona and New Mexico, in southern Texas, and scattered throughout the Rust Belt, were impressively predicted by the experts and their ratings, reflected in the standout blue coloring in the plot above. The experts were also able to pin down the close races, like the ones in southern New Mexico and in Maine. Overall, I think the average expert ratings predicted the congressional races at the district level very well, despite being just one predictor (that is a culmination of many predictors considered by the experts) in my model.

# My 2022 Model and Forecast, Updated

## My New Model

```{r 2022 prediction data cleaning, include = FALSE}
# # Selecting columns
# avg_ratings <- expert_ratings %>% 
#   select(year, state, district, avg_rating)
# # Joining the data and nesting by state and district
# train_data <- avg_ratings %>% 
#   filter(year != 2022) %>% 
#   # left join as there aren't ratings for every district
#   left_join(historical_results, by = c("year", "state", "district")) %>% 
#   group_by(state, district) %>% 
#   filter(n() > 1) %>% # Filtering out single data rows
#   group_nest() %>% 
#   mutate(data = map(data, ~unnest(., cols = c())))
# test_data <- avg_ratings %>% 
#   filter(year == 2022) %>% 
#   group_by(state, district) %>% 
#   group_nest() %>% 
#   mutate(data = map(data, ~unnest(., cols = c())))
```

```{r prediction models, include = FALSE}
# # Building TERRIBLE models
# models <- train_data %>% 
#   mutate(model = map(data, ~lm(dem_votes_major_percent ~ avg_rating, 
#                                   data = .x))) %>% 
#   select(-data)
# # Extracting TERRIBLE model results
# model_results <- models %>% 
#   mutate(r_squared = map_dbl(model, ~summary(.x)$r.squared))
# # Predicting 2022 with a TERRIBLE model
# pred_2022 <- test_data %>%
#   # inner join as there may not be historical models for some districts
#   inner_join(models, by = c("state", "district")) %>% 
#   mutate(pred = map_dbl(.x = model, .y = data, ~predict(object = .x, newdata = as.data.frame(.y)))) %>%
#   select(state, district, pred)
```

## My New Forecast


```{r forecast printout, include = FALSE}
# export_table(pred_2022, format = "html")
```
---

**References**

[1] Cook Political Report. (2002). House Race Ratings. https://www.cookpolitical.com/ratings/house-race-ratings

[2] Inside Elections. (2022). House Ratings. https://insideelections.com/ratings/house

[3] Sabato's Crystal Ball. (2022). House Race Ratings. https://centerforpolitics.org/crystalball/2022-house/